# -*- coding: utf-8 -*-




import os
from scipy import spatial
import numpy as np
import gensim
import nltk
from keras.models import load_model
import unicodedata

import theano
theano.config.optimizer="None"


model=load_model('LSTM5000.h5')
mod = gensim.models.Word2Vec.load('/home/deepak/bot/apnews_sg/word2vec.bin');
while(True):
    x=raw_input("Enter the message:");
    sentend=np.ones((300L,),dtype=np.float32) 

    sent=nltk.word_tokenize(x.lower())
    sentvec = [mod[w] for w in sent if w in mod.vocab]

    sentvec[14:]=[]
    sentvec.append(sentend)
    if len(sentvec)<15:
        for i in range(15-len(sentvec)):
            sentvec.append(sentend) 
    sentvec=np.array([sentvec])
    
    predictions = model.predict(sentvec)
    outputlist=[mod.most_similar([predictions[0][i]])[0][0] for i in range(15)]
    output=' '.join(outputlist)
    #unicodedata.normalize('NFKD', output).encode('String','ignore')
    #output.split()
    x = nltk.word_tokenize(output)
    for item in x:
        if(item == "kleiser"):
            x.remove("kleiser")
    for item in x:
        if(item == "kleiser"):
            x.remove("kleiser")

    for item in x:
        if(item == "kleiser"):
            x.remove("kleiser")
    for item in x:
        if(item == "kleiser"):
            x.remove("kleiser")
    for item in x:
        if(item == "karluah"):
            x.remove("karluah")
    #print x
    output = " ".join(str(xx) for xx in x)
    print output

    
    
       
    
    #print output

